{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eTiLgSQykSgN"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "try:\n",
        "    import qdax\n",
        "except:\n",
        "    print(\"QDax not found. Installing...\")\n",
        "    !pip install git+https://github.com/EduardGilM/OI-QDax\n",
        "    import qdax\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NtsKmIC1kVH3"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install ipympl |tail -n 1\n",
        "# %matplotlib widget\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()\n",
        "\n",
        "import os\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import functools\n",
        "import time\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from qdax.core.map_elites import MAPElites\n",
        "from qdax.core.containers.mapelites_repertoire import compute_cvt_centroids, MapElitesRepertoire\n",
        "from qdax import environments\n",
        "from qdax.tasks.brax_envs import scoring_function_brax_envs as scoring_function\n",
        "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
        "from qdax.core.neuroevolution.networks.networks import MLP\n",
        "from qdax.core.emitters.mutation_operators import isoline_variation\n",
        "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
        "from qdax.utils.plotting_utils import plot_map_elites_results\n",
        "\n",
        "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
        "\n",
        "from jax.flatten_util import ravel_pytree\n",
        "\n",
        "from IPython.display import HTML\n",
        "from brax.v1.io import html\n",
        "\n",
        "from qdax.custom_types import Descriptor\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "  from jax.tools import colab_tpu\n",
        "  colab_tpu.setup_tpu()\n",
        "\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W8FpHUVXkXaW"
      },
      "outputs": [],
      "source": [
        "#@title QD Training Definitions Fields\n",
        "#@markdown ---\n",
        "batch_size = 2 #@param {type:\"number\"}\n",
        "env_name = 'halfcheetah_oi'\n",
        "episode_length = 10 #@param {type:\"integer\"}\n",
        "num_iterations = 100 #@param {type:\"integer\"}\n",
        "seed = 42 #@param {type:\"integer\"}\n",
        "policy_hidden_layer_sizes = (64, 64) #@param {type:\"raw\"}\n",
        "iso_sigma = 0.005 #@param {type:\"number\"}\n",
        "line_sigma = 0.05 #@param {type:\"number\"}\n",
        "num_init_cvt_samples = 50000 #@param {type:\"integer\"}\n",
        "num_centroids = 1024 #@param {type:\"integer\"}\n",
        "min_bd = -12 #@param {type:\"number\"}\n",
        "max_bd = 12  #@param {type:\"number\"}\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5UXWpFxAkYg4"
      },
      "outputs": [],
      "source": [
        "# Init environment\n",
        "env = environments.create(env_name, episode_length=episode_length,fixed_init_state=True, qdax_wrappers_kwargs=[{\"max_sequence_length\": 100,\"lz76_window\": 50,\"oi_window\": 20}])\n",
        "\n",
        "# Init a random key\n",
        "random_key = jax.random.PRNGKey(seed)\n",
        "\n",
        "# Init policy network\n",
        "policy_layer_sizes = policy_hidden_layer_sizes + (env.action_size,)\n",
        "policy_network = MLP(\n",
        "    layer_sizes=policy_layer_sizes,\n",
        "    kernel_init=jax.nn.initializers.lecun_uniform(),\n",
        "    final_activation=jnp.tanh,\n",
        ")\n",
        "\n",
        "# Init population of controllers\n",
        "random_key, subkey = jax.random.split(random_key)\n",
        "keys = jax.random.split(subkey, num=batch_size)\n",
        "fake_batch = jnp.zeros(shape=(batch_size, env.observation_size))\n",
        "init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
        "\n",
        "\n",
        "# Create the initial environment states\n",
        "random_key, subkey = jax.random.split(random_key)\n",
        "keys = jnp.repeat(jnp.expand_dims(subkey, axis=0), repeats=batch_size, axis=0)\n",
        "reset_fn = jax.jit(jax.vmap(env.reset))\n",
        "init_states = reset_fn(keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wa5vyMnDkZFt"
      },
      "outputs": [],
      "source": [
        "# Define the fonction to play a step with the policy in the environment\n",
        "def play_step_fn(\n",
        "  env_state,\n",
        "  policy_params,\n",
        "  random_key,\n",
        "):\n",
        "    \"\"\"\n",
        "    Play an environment step and return the updated state and the transition.\n",
        "    \"\"\"\n",
        "\n",
        "    actions = policy_network.apply(policy_params, env_state.obs)\n",
        "\n",
        "    state_desc = env_state.info[\"state_descriptor\"]\n",
        "    next_state = env.step(env_state, actions)\n",
        "\n",
        "    transition = QDTransition(\n",
        "        obs=env_state.obs,\n",
        "        next_obs=next_state.obs,\n",
        "        rewards=next_state.reward,\n",
        "        dones=next_state.done,\n",
        "        actions=actions,\n",
        "        truncations=next_state.info[\"truncation\"],\n",
        "        state_desc=state_desc,\n",
        "        next_state_desc=next_state.info[\"state_descriptor\"],\n",
        "    )\n",
        "\n",
        "    return next_state, policy_params, random_key, transition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xlD_aqUWkacf"
      },
      "outputs": [],
      "source": [
        "def get_mixing_emitter(batch_size: int) -> MixingEmitter:\n",
        "    \"\"\"Create a mixing emitter with a given batch size.\"\"\"\n",
        "    variation_fn = functools.partial(isoline_variation, iso_sigma=0.05, line_sigma=0.1)\n",
        "    mixing_emitter = MixingEmitter(\n",
        "        mutation_fn=lambda x, y: (x, y),\n",
        "        variation_fn=variation_fn,\n",
        "        variation_percentage=1.0,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    return mixing_emitter\n",
        "\n",
        "def bd_extraction_fn(transitions, mask):\n",
        "        # Obtener el último descriptor de estado válido\n",
        "        last_valid_index = jnp.sum(1.0 - mask, axis=1) - 1\n",
        "        last_valid_index = jnp.clip(last_valid_index, 0, transitions.next_state_desc.shape[1] - 1)\n",
        "        batch_indices = jnp.arange(transitions.next_state_desc.shape[0])\n",
        "\n",
        "        # Extraer los descriptores finales y asegurar la forma correcta\n",
        "        final_descriptors = transitions.next_state_desc[batch_indices, last_valid_index.astype(jnp.int32)]\n",
        "\n",
        "        # Asegurar que la forma sea (batch_size, 2)\n",
        "        if len(final_descriptors.shape) > 2:\n",
        "            final_descriptors = final_descriptors.reshape(final_descriptors.shape[0], -1)\n",
        "\n",
        "        return final_descriptors\n",
        "\n",
        "scoring_fn = functools.partial(\n",
        "    scoring_function,\n",
        "    init_states=init_states,\n",
        "    episode_length=episode_length,\n",
        "    play_step_fn=play_step_fn,\n",
        "    behavior_descriptor_extractor=bd_extraction_fn,\n",
        ")\n",
        "mixing_emitter = get_mixing_emitter(batch_size)\n",
        "reward_offset = environments.reward_offset[env_name]\n",
        "metrics_fn = functools.partial(default_qd_metrics, qd_offset=reward_offset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImVmg6X5kcbS",
        "outputId": "d2abf6c2-e45d-4fbd-9145-e9e657368c66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/qdax/core/map_elites.py:81: UserWarning: This type of repertoire does not store the extra scores computed by the scoring function\n",
            "  repertoire = MapElitesRepertoire.init(\n"
          ]
        }
      ],
      "source": [
        "# Instantiate MAP-Elites\n",
        "map_elites = MAPElites(\n",
        "    scoring_function=scoring_fn,\n",
        "    emitter=mixing_emitter,\n",
        "    metrics_function=metrics_fn,\n",
        ")\n",
        "\n",
        "# Compute the centroids\n",
        "centroids, random_key = compute_cvt_centroids(\n",
        "    num_descriptors=env.behavior_descriptor_length,\n",
        "    num_init_cvt_samples=num_init_cvt_samples,\n",
        "    num_centroids=num_centroids,\n",
        "    minval=min_bd,\n",
        "    maxval=max_bd,\n",
        "    random_key=random_key,\n",
        ")\n",
        "\n",
        "# Compute initial repertoire and emitter state\n",
        "repertoire, emitter_state, random_key = map_elites.init(init_variables, centroids, random_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB7NxbpikeEF"
      },
      "outputs": [],
      "source": [
        "log_period = 10\n",
        "num_loops = int(num_iterations / log_period)\n",
        "\n",
        "csv_logger = CSVLogger(\n",
        "    \"mapelites-logs.csv\",\n",
        "    header=[\"loop\", \"iteration\", \"qd_score\", \"max_fitness\", \"coverage\", \"time\"]\n",
        ")\n",
        "all_metrics = {}\n",
        "\n",
        "# main loop\n",
        "map_elites_scan_update = map_elites.scan_update\n",
        "for i in range(num_loops):\n",
        "    start_time = time.time()\n",
        "    # main iterations\n",
        "    (repertoire, emitter_state, random_key,), metrics = jax.lax.scan(\n",
        "        map_elites_scan_update,\n",
        "        (repertoire, emitter_state, random_key),\n",
        "        (),\n",
        "        length=log_period,\n",
        "    )\n",
        "    timelapse = time.time() - start_time\n",
        "\n",
        "    # log metrics\n",
        "    logged_metrics = {\"time\": timelapse, \"loop\": 1+i, \"iteration\": 1 + i*log_period}\n",
        "    for key, value in metrics.items():\n",
        "        # take last value\n",
        "        logged_metrics[key] = value[-1]\n",
        "\n",
        "        # take all values\n",
        "        if key in all_metrics.keys():\n",
        "            all_metrics[key] = jnp.concatenate([all_metrics[key], value])\n",
        "        else:\n",
        "            all_metrics[key] = value\n",
        "\n",
        "    csv_logger.log(logged_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk4ywfsbkfOP"
      },
      "outputs": [],
      "source": [
        "#@title Visualization\n",
        "\n",
        "# create the x-axis array\n",
        "env_steps = jnp.arange(num_iterations) * episode_length * batch_size\n",
        "\n",
        "# create the plots and the grid\n",
        "fig, axes = plot_map_elites_results(env_steps=env_steps, metrics=all_metrics, repertoire=repertoire, min_bd=min_bd, max_bd=max_bd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_0aUfzAkgSR"
      },
      "outputs": [],
      "source": [
        "repertoire_path = \"./last_repertoire/\"\n",
        "os.makedirs(repertoire_path, exist_ok=True)\n",
        "repertoire.save(path=repertoire_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_LGSjImkgpx"
      },
      "outputs": [],
      "source": [
        "# Init population of policies\n",
        "random_key, subkey = jax.random.split(random_key)\n",
        "fake_batch = jnp.zeros(shape=(env.observation_size,))\n",
        "fake_params = policy_network.init(subkey, fake_batch)\n",
        "\n",
        "_, reconstruction_fn = ravel_pytree(fake_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNHh1yq-khrR"
      },
      "outputs": [],
      "source": [
        "repertoire = MapElitesRepertoire.load(reconstruction_fn=reconstruction_fn, path=repertoire_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRk8ncvFkivn"
      },
      "outputs": [],
      "source": [
        "best_idx = jnp.argmax(repertoire.fitnesses)\n",
        "best_fitness = jnp.max(repertoire.fitnesses)\n",
        "best_bd = repertoire.descriptors[best_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0KQWrDKkjtR",
        "outputId": "df3a0cb7-497d-4eed-f4ce-738546991857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best fitness in the repertoire: 11.88\n",
            " Behavior descriptor of the best individual in the repertoire: [131. 131.]\n",
            " Index in the repertoire of this individual: 321\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f\"Best fitness in the repertoire: {best_fitness:.2f}\\n\",\n",
        "    f\"Behavior descriptor of the best individual in the repertoire: {best_bd}\\n\",\n",
        "    f\"Index in the repertoire of this individual: {best_idx}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V784JXnVkkrR"
      },
      "outputs": [],
      "source": [
        "my_params = jax.tree_util.tree_map(\n",
        "    lambda x: x[best_idx],\n",
        "    repertoire.genotypes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdtSNaAZkl6D"
      },
      "outputs": [],
      "source": [
        "jit_env_reset = jax.jit(env.reset)\n",
        "jit_env_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(policy_network.apply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w758-azqknAB"
      },
      "outputs": [],
      "source": [
        "rollout = []\n",
        "rng = jax.random.PRNGKey(seed=42)\n",
        "state = jit_env_reset(rng=rng)\n",
        "while not state.done:\n",
        "    rollout.append(state)\n",
        "    action = jit_inference_fn(my_params, state.obs)\n",
        "    state = jit_env_step(state, action)\n",
        "    print(action)\n",
        "\n",
        "print(f\"The trajectory of this individual contains {len(rollout)} transitions.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2LAHxb0kn-N"
      },
      "outputs": [],
      "source": [
        "HTML(html.render(env.sys, [s.qp for s in rollout[:500]]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
